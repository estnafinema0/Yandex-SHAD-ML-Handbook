{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "## Классификация FashionMNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_hXsRIwarQFj"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "\n",
        "def parse_pytorch_model(model_str):\n",
        "    def parse_layer(layer_str):\n",
        "        layer_info = {}\n",
        "        layer_name, params = layer_str.split(\"(\", 1)\n",
        "        params = params.rstrip(\")\")\n",
        "        layer_info[\"type\"] = layer_name.strip()\n",
        "        param_dict = {}\n",
        "        for param in params.split(\", \"):\n",
        "            if \"=\" in param:\n",
        "                key, value = param.split(\"=\")\n",
        "                param_dict[key.strip()] = eval(value.strip())\n",
        "            else:\n",
        "                param_dict[param.strip()] = None\n",
        "        layer_info[\"parameters\"] = param_dict\n",
        "        return layer_info\n",
        "\n",
        "    model_dict = {}\n",
        "    lines = model_str.splitlines()\n",
        "    model_name = lines[0].strip(\"()\")\n",
        "    model_dict[\"model_name\"] = model_name\n",
        "    model_dict[\"layers\"] = []\n",
        "\n",
        "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
        "    for line in lines[1:]:\n",
        "        line = line.strip()\n",
        "        match = layer_regex.match(line)\n",
        "        if match:\n",
        "            index, layer = match.groups()\n",
        "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
        "    return model_dict\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_aTuAu-drQFj"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL9U2SlfrQFk"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sZxttWarQFl",
        "outputId": "dcd20dc6-265d-42d2-81d2-d58b934f19b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-09 12:25:29--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-04-09 12:25:30--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.1’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-04-09 12:25:30 (107 MB/s) - ‘hw_overfitting_data_dict.1’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SQAZ-ygjrQFl"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1r1o2HDMrQFm"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "aYcL28OsgSq8",
        "outputId": "3fa3af84-4e12-4c95-f592-c2d6d17c65b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 9.32MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 208kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.85MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 17.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 5')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "class FashionMNISTClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FashionMNISTClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model_task_1 = FashionMNISTClassifier()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "218b4fac-b28b-47f1-f46e-4d0303b6ed4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionMNISTClassifier(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "026027ef-aa59-4104-800f-8044fd174474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YJnU14bdnZa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f7f248f-4413-4bbb-ed6a-2816220e4c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8, Loss: 0.4193, Train Acc: 0.8879, Test Acc: 0.8757\n",
            "Epoch 2/8, Loss: 0.2728, Train Acc: 0.9157, Test Acc: 0.9006\n",
            "Epoch 3/8, Loss: 0.2313, Train Acc: 0.9311, Test Acc: 0.9099\n",
            "Epoch 4/8, Loss: 0.1980, Train Acc: 0.9426, Test Acc: 0.9147\n",
            "Epoch 5/8, Loss: 0.1725, Train Acc: 0.9506, Test Acc: 0.9181\n",
            "Epoch 6/8, Loss: 0.1481, Train Acc: 0.9582, Test Acc: 0.9193\n",
            "Epoch 7/8, Loss: 0.1265, Train Acc: 0.9613, Test Acc: 0.9165\n",
            "Epoch 8/8, Loss: 0.1071, Train Acc: 0.9623, Test Acc: 0.9100\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_task_1.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 8\n",
        "for epoch in range(num_epochs):\n",
        "    model_task_1.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_data_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_task_1(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_data_loader)\n",
        "    train_acc = get_accuracy(model_task_1, train_data_loader)\n",
        "    test_acc = get_accuracy(model_task_1, test_data_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "362a4581-60bf-4afe-adf5-163abb322cee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.96228\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ef6af8-55a2-4dca-a873-ac4765bc9654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.91\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Test accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzCPxmI6rQFq"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOIrKe65rQFq",
        "outputId": "b0dab5b1-8bec-4c7e-fece-a31a6656f5c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_fmnist_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_fmnist_data_dict.npy\"\n",
        "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "    \"model_task_1\": parse_pytorch_model(str(model_task_1)),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4Z83WX6rQFq"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_task_1.json` в задачу Separation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Py3 Research",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}